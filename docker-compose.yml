services:
  kai-server:
    build: ./server
    image: kai-server:local
    ports:
      - "8000:8000"
    environment:
      OLLAMA_URL: http://host.docker.internal:11434
      OLLAMA_MODEL: llama3.1
    restart: unless-stopped
